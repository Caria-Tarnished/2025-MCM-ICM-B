{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Deep_learning_study\\MCM\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "# 引入需要的库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize, Bounds\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from prophet import Prophet\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 模块1：数据预处理与特征工程\n",
    "# --------------------------\n",
    "class DataProcessor:\n",
    "    def __init__(self, pareto_path, tourism_path, tourists_path):\n",
    "        self.pareto_path = pareto_path\n",
    "        self.tourism_path = tourism_path\n",
    "        self.tourists_path = tourists_path\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"加载所有数据集并合并\"\"\"\n",
    "        # 读取Pareto前沿数据\n",
    "        self.pareto_df = pd.read_excel(self.pareto_path)\n",
    "        \n",
    "        # 读取每日旅游数据（包含区域信息）\n",
    "        self.tourism_df = pd.read_excel(self.tourism_path)\n",
    "        self.tourism_df['date'] = pd.to_datetime(self.tourism_df['date'])\n",
    "        self.tourism_df = self.tourism_df[self.tourism_df['carbon'] >= 0]  # 清除负碳排放\n",
    "        \n",
    "        # 读取月度游客数据\n",
    "        self.tourists_monthly_df = pd.read_excel(self.tourists_path)\n",
    "        self.tourists_monthly_df['date'] = pd.to_datetime(self.tourists_monthly_df['date'])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def feature_engineering(self):\n",
    "        \"\"\"生成关键特征\"\"\"\n",
    "        # 按区域计算平均碳排放\n",
    "        region_carbon = self.tourism_df.groupby('region')['carbon'].mean().reset_index()\n",
    "        region_carbon.columns = ['region', 'region_carbon_avg']\n",
    "        self.tourism_df = pd.merge(self.tourism_df, region_carbon, on='region', how='left')\n",
    "        \n",
    "        # 计算游客数量与碳排放的比值（旅游效率）\n",
    "        self.tourism_df['efficiency'] = self.tourism_df['tourists'] / (self.tourism_df['carbon'] + 1e-6)\n",
    "        \n",
    "        # 合并月度数据到每日数据\n",
    "        self.tourism_df['month'] = self.tourism_df['date'].dt.to_period('M')\n",
    "        self.tourists_monthly_df['month'] = self.tourists_monthly_df['date'].dt.to_period('M')\n",
    "        merged_df = pd.merge(\n",
    "            self.tourism_df,\n",
    "            self.tourists_monthly_df[['month', 'tourists']],\n",
    "            on='month',\n",
    "            suffixes=('_daily', '_monthly')\n",
    "        )\n",
    "        \n",
    "        return merged_df\n",
    "    \n",
    "    def normalize_data(self, df):\n",
    "        \"\"\"数据标准化\"\"\"\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_data = scaler.fit_transform(df[['Economic_Profit', 'Glacier_Retreat', 'Social_Satisfaction']])\n",
    "        df[['profit_norm', 'glacier_norm', 'social_norm']] = scaled_data\n",
    "        return df, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 模块2：多目标优化模型\n",
    "# --------------------------\n",
    "class TourismOptimizer:\n",
    "    def __init__(self, data, params):\n",
    "        \"\"\"\n",
    "        :param data: 预处理后的数据\n",
    "        :param params: 模型参数\n",
    "            - weights: 目标权重 [经济, 环境, 社会]\n",
    "            - max_tourists: 最大游客容量\n",
    "            - carbon_cap: 碳排放上限\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.weights = params['weights']\n",
    "        self.max_tourists = params['max_tourists']\n",
    "        self.carbon_cap = params['carbon_cap']\n",
    "        \n",
    "    def objective(self, x):\n",
    "        \"\"\"多目标优化函数\"\"\"\n",
    "        # x = [游客数量, 碳排放量, 基础设施投资比例]\n",
    "        profit = x[0] * 5000  # 假设每位游客贡献$5000经济收益\n",
    "        carbon_penalty = np.maximum(x[1] - self.carbon_cap, 0) * 1e6  # 超碳排放罚款\n",
    "        social_score = 1 / (1 + np.exp(-x[2]))  # 基础设施投资对社会满意度的影响\n",
    "        \n",
    "        # 加权目标（最大化经济和社会，最小化环境）\n",
    "        return -(self.weights[0]*profit - self.weights[1]*carbon_penalty + self.weights[2]*social_score)\n",
    "    \n",
    "    def constraints(self):\n",
    "        \"\"\"动态约束条件\"\"\"\n",
    "        cons = [\n",
    "            {'type': 'ineq', 'fun': lambda x: self.max_tourists - x[0]},  # 游客上限\n",
    "            {'type': 'ineq', 'fun': lambda x: self.carbon_cap - x[1]},    # 碳排放上限\n",
    "            {'type': 'ineq', 'fun': lambda x: x[2]}                       # 投资比例非负\n",
    "        ]\n",
    "        return cons\n",
    "    \n",
    "    def optimize(self):\n",
    "        \"\"\"执行优化\"\"\"\n",
    "        bounds = Bounds(\n",
    "            [0, 0, 0],                    # 下限\n",
    "            [self.max_tourists, np.inf, 1] # 上限\n",
    "        )\n",
    "        \n",
    "        res = minimize(\n",
    "            self.objective,\n",
    "            x0=[self.max_tourists/2, self.carbon_cap/2, 0.5],\n",
    "            method='SLSQP',\n",
    "            bounds=bounds,\n",
    "            constraints=self.constraints()\n",
    "        )\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 模块3：加入时间序列预测\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "class TimeSeriesPredictor:\n",
    "    def __init__(self, data, target_column='tourists', date_column='date'):\n",
    "        self.data = data.sort_values(date_column)\n",
    "        self.target = target_column\n",
    "        self.date_col = date_column\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        \n",
    "    def preprocess(self, forecast_days=30):\n",
    "        \"\"\"数据预处理与特征工程\"\"\"\n",
    "        # 生成时序特征\n",
    "        df = self.data.set_index(self.date_col)[self.target].resample('D').mean().ffill()\n",
    "        df = pd.DataFrame(df)\n",
    "        df['day_of_week'] = df.index.dayofweek\n",
    "        df['day_of_month'] = df.index.day\n",
    "        df['month'] = df.index.month\n",
    "        return df\n",
    "    \n",
    "    def prophet_predict(self, periods=365):\n",
    "        \"\"\"使用Facebook Prophet进行预测\"\"\"\n",
    "        df = self.data[[self.date_col, self.target]].rename(columns={self.date_col: 'ds', self.target: 'y'})\n",
    "\n",
    "        model = Prophet(\n",
    "            yearly_seasonality=True,\n",
    "            weekly_seasonality=True,\n",
    "            daily_seasonality=False,\n",
    "            changepoint_prior_scale=0.05\n",
    "        )\n",
    "        model.add_country_holidays(country_name='US')\n",
    "        model.fit(df)\n",
    "        \n",
    "        future = model.make_future_dataframe(periods=periods)\n",
    "        forecast = model.predict(future)\n",
    "        return forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "    \n",
    "    def lstm_predict(self, look_back=15, forecast_days=30):\n",
    "        \"\"\"使用LSTM神经网络进行预测\"\"\"\n",
    "        dataset = self.data[self.target].values.reshape(-1, 1)\n",
    "        dataset = self.scaler.fit_transform(dataset)\n",
    "        \n",
    "        # 在数据集创建之前，添加调试信息\n",
    "        print(f\"Dataset length: {len(dataset)}\")\n",
    "        print(f\"Look back: {look_back}, Forecast days: {forecast_days}\")\n",
    "        \n",
    "        # 创建时序数据集\n",
    "        X, Y = [], []\n",
    "        for i in range(len(dataset) - look_back - forecast_days):\n",
    "            X.append(dataset[i:(i + look_back), 0])\n",
    "            Y.append(dataset[i + look_back:i + look_back + forecast_days, 0])\n",
    "        \n",
    "        # 检查是否有足够的数据点\n",
    "        if len(X) == 0 or len(Y) == 0:\n",
    "            raise ValueError(\"Not enough data to create the specified look_back and forecast_days sequences.\")\n",
    "        \n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        \n",
    "        # 构建LSTM模型\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(50, return_sequences=True, input_shape=(look_back, 1)))\n",
    "        model.add(LSTM(50))\n",
    "        model.add(Dense(forecast_days))\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "        \n",
    "        # 训练模型\n",
    "        model.fit(X.reshape(X.shape[0], X.shape[1], 1), Y, \n",
    "                epochs=50, batch_size=32, verbose=0)\n",
    "        \n",
    "        # 生成预测\n",
    "        last_sequence = dataset[-look_back:]\n",
    "        predictions = model.predict(last_sequence.reshape(1, look_back, 1))\n",
    "        return self.scaler.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "    def hybrid_predict(self, periods=365):\n",
    "        \"\"\"混合预测方法：Prophet + LSTM残差修正\"\"\"\n",
    "        # 第一阶段：Prophet基础预测\n",
    "        prophet_result = self.prophet_predict(periods)\n",
    "        \n",
    "        # 第二阶段：计算残差\n",
    "        residuals = self.data[self.target] - prophet_result['yhat'][:-periods]\n",
    "        \n",
    "        # 确保残差的长度与LSTM预测的长度一致\n",
    "        lstm_residuals = self.lstm_predict(look_back=15, forecast_days=periods)\n",
    "        \n",
    "        # 合并结果\n",
    "        final = prophet_result.copy()\n",
    "        # 使用预测周期内的残差进行修正\n",
    "        final['hybrid'] = final['yhat'][-periods:] + lstm_residuals\n",
    "        return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# 模块4：可视化与报告生成\n",
    "# --------------------------\n",
    "class Visualizer:\n",
    "    @staticmethod\n",
    "    def plot_pareto_front(df):\n",
    "        \"\"\"3D帕累托前沿可视化\"\"\"\n",
    "        fig = plt.figure(figsize=(12, 8))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        \n",
    "        xs = df['profit_norm']\n",
    "        ys = df['glacier_norm']\n",
    "        zs = df['social_norm']\n",
    "        \n",
    "        ax.scatter(xs, ys, zs, c=zs, cmap=cm.viridis, marker='o')\n",
    "        ax.set_xlabel('Economic Profit')\n",
    "        ax.set_ylabel('Glacier Retreat')\n",
    "        ax.set_zlabel('Social Satisfaction')\n",
    "        plt.title(\"3D Pareto Front\")\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_scenario_comparison(results):\n",
    "        \"\"\"情景对比雷达图\"\"\"\n",
    "        labels = ['Economic', 'Environment', 'Social']\n",
    "        angles = np.linspace(0, 2*np.pi, len(labels), endpoint=False).tolist()\n",
    "        angles += angles[:1]  # 闭合雷达图\n",
    "\n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        ax = fig.add_subplot(111, polar=True)\n",
    "\n",
    "        # 经济优先\n",
    "        economic_values = [\n",
    "            results['economic']['profit'],\n",
    "            -results['economic']['carbon'],  # 负值表示最小化目标\n",
    "            results['economic']['social_score']\n",
    "        ]\n",
    "        economic_values += economic_values[:1]  # 闭合雷达图\n",
    "        ax.plot(angles, economic_values, 'o-', linewidth=2, label='Economic Priority')\n",
    "\n",
    "        # 环境优先\n",
    "        environmental_values = [\n",
    "            results['environmental']['profit'],\n",
    "            -results['environmental']['carbon'],\n",
    "            results['environmental']['social_score']\n",
    "        ]\n",
    "        environmental_values += environmental_values[:1]\n",
    "        ax.plot(angles, environmental_values, 'o-', linewidth=2, label='Environmental Priority')\n",
    "\n",
    "        # 社会优先\n",
    "        social_values = [\n",
    "            results['social']['profit'],\n",
    "            -results['social']['carbon'],\n",
    "            results['social']['social_score']\n",
    "        ]\n",
    "        social_values += social_values[:1]\n",
    "        ax.plot(angles, social_values, 'o-', linewidth=2, label='Social Priority')\n",
    "\n",
    "        ax.set_thetagrids(np.degrees(angles[:-1]), labels)\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.title(\"Scenario Comparison\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:26:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:26:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 48\n",
      "Look back: 15, Forecast days: 30\n",
      "1/1 [==============================] - 0s 499ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:26:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:26:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 358\n",
      "Look back: 15, Forecast days: 30\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "Index(['date', 'tourists_daily', 'carbon', 'region', 'region_carbon_avg',\n",
      "       'efficiency', 'month', 'tourists_monthly'],\n",
      "      dtype='object')\n",
      "Integrated Forecast DataFrame:\n",
      "           0  tourists_monthly\n",
      "0  33.589463               NaN\n",
      "1  33.589463               NaN\n",
      "2  33.589463               NaN\n",
      "3  33.589463               NaN\n",
      "4  33.589463               NaN\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 388 entries, 0 to 1972-06-30 00:00:00.000000357\n",
      "Data columns (total 2 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   0                 358 non-null    float64\n",
      " 1   tourists_monthly  0 non-null      float32\n",
      "dtypes: float32(1), float64(1)\n",
      "memory usage: 7.6+ KB\n",
      "None\n",
      "\n",
      "Merged Data 'tourists_monthly' Column Before Update:\n",
      "0    33.589463\n",
      "1    33.589463\n",
      "2    33.589463\n",
      "3    33.589463\n",
      "4    33.589463\n",
      "Name: tourists_monthly, dtype: float64\n",
      "<class 'pandas.core.series.Series'>\n",
      "Int64Index: 358 entries, 0 to 357\n",
      "Series name: tourists_monthly\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "358 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 5.6 KB\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(merged_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtourists_monthly\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39minfo())  \u001b[38;5;66;03m# 打印结构信息\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# 更新游客数据\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m \u001b[43mmerged_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtourists_monthly\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m integrated_forecast\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# 再次检查更新后的 merged_data['tourists_monthly']\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMerged Data \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtourists_monthly\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Column After Update:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32me:\\Deep_learning_study\\MCM\\lib\\site-packages\\pandas\\core\\frame.py:3970\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3968\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array(key, value)\n\u001b[0;32m   3969\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m-> 3970\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_frame_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   3972\u001b[0m     is_list_like(value)\n\u001b[0;32m   3973\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[0;32m   3974\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_indexer_for([key])) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[0;32m   3975\u001b[0m ):\n\u001b[0;32m   3976\u001b[0m     \u001b[38;5;66;03m# Column to set is duplicated\u001b[39;00m\n\u001b[0;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n",
      "File \u001b[1;32me:\\Deep_learning_study\\MCM\\lib\\site-packages\\pandas\\core\\frame.py:4100\u001b[0m, in \u001b[0;36mDataFrame._set_item_frame_value\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4098\u001b[0m len_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_scalar(cols) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cols)\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m len_cols \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[1;32m-> 4100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns must be same length as key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4102\u001b[0m \u001b[38;5;66;03m# align right-hand-side columns if self.columns\u001b[39;00m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;66;03m# is multi-index and self[key] is a sub-frame\u001b[39;00m\n\u001b[0;32m   4104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   4105\u001b[0m     loc, (\u001b[38;5;28mslice\u001b[39m, Series, np\u001b[38;5;241m.\u001b[39mndarray, Index)\n\u001b[0;32m   4106\u001b[0m ):\n",
      "\u001b[1;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# 模块5: 主程序\n",
    "# --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 初始化数据处理器\n",
    "    processor = DataProcessor(\n",
    "        pareto_path=\"pareto_data.xlsx\",\n",
    "        tourism_path=\"tourism_data.xlsx\",\n",
    "        tourists_path=\"tourists_data.xlsx\"\n",
    "    )\n",
    "    merged_data = processor.load_data().feature_engineering()\n",
    "        # ========== 新增时间序列预测模块 ==========\n",
    "    # 游客数量预测\n",
    "    tourist_predictor = TimeSeriesPredictor(\n",
    "        processor.tourists_monthly_df, \n",
    "        target_column='tourists',\n",
    "        date_column='date'\n",
    "    )\n",
    "    prophet_forecast = tourist_predictor.prophet_predict(periods=1)  # 预测未来1个月\n",
    "    lstm_forecast = tourist_predictor.lstm_predict(forecast_days=30)  # 预测未来30天\n",
    "    \n",
    "    # 碳排放预测\n",
    "    carbon_predictor = TimeSeriesPredictor(\n",
    "        processor.tourism_df,\n",
    "        target_column='carbon',\n",
    "        date_column='date'\n",
    "    )\n",
    "    carbon_forecast = carbon_predictor.hybrid_predict(periods=30)\n",
    "    \n",
    "    # 将预测结果整合到优化模型输入数据\n",
    "    def integrate_forecasts(original, forecast, freq='D'):\n",
    "        \"\"\"融合历史数据与预测数据\"\"\"\n",
    "        forecast_df = forecast.set_index('ds') if 'ds' in forecast.columns else pd.DataFrame(\n",
    "            index=pd.date_range(start=original.index[-1], periods=len(forecast), freq=freq),\n",
    "            data=forecast\n",
    "        )\n",
    "        return pd.concat([original, forecast_df], axis=0)\n",
    "    \n",
    "    # 检验\n",
    "    print(merged_data.columns)\n",
    "    \n",
    "    # 检查 integrate_forecasts 返回的 DataFrame\n",
    "    lstm_forecast_df = pd.DataFrame(\n",
    "        lstm_forecast,\n",
    "        columns=['tourists_monthly']  # 使用与目标列相同的名称\n",
    "    )\n",
    "\n",
    "    # 调用 integrate_forecasts 并检查返回值\n",
    "    integrated_forecast = integrate_forecasts(\n",
    "        merged_data['tourists_monthly'], \n",
    "        lstm_forecast_df, \n",
    "        freq='M'\n",
    "    )\n",
    "\n",
    "    # 打印 integrated_forecast 的信息\n",
    "    print(\"Integrated Forecast DataFrame:\")\n",
    "    print(integrated_forecast.head())  # 打印前几行\n",
    "    print(integrated_forecast.info())  # 打印结构信息\n",
    "\n",
    "    # 检查 merged_data['tourists_monthly'] 的内容\n",
    "    print(\"\\nMerged Data 'tourists_monthly' Column Before Update:\")\n",
    "    print(merged_data['tourists_monthly'].head())  # 打印前几行\n",
    "    print(merged_data['tourists_monthly'].info())  # 打印结构信息\n",
    "\n",
    "    # 更新游客数据\n",
    "    merged_data['tourists_monthly'] = integrated_forecast\n",
    "\n",
    "    # 再次检查更新后的 merged_data['tourists_monthly']\n",
    "    print(\"\\nMerged Data 'tourists_monthly' Column After Update:\")\n",
    "    print(merged_data['tourists_monthly'].head())  # 打印前几行\n",
    "    print(merged_data['tourists_monthly'].info())  # 打印结构信息\n",
    "    \n",
    "\n",
    "\n",
    "    # 更新碳排放数据\n",
    "    merged_data['carbon'] = integrate_forecasts(\n",
    "        merged_data['carbon'],\n",
    "        carbon_forecast[['ds', 'hybrid']].rename(columns={'ds': 'date', 'hybrid': 'carbon'}),\n",
    "        freq='D'\n",
    "    )\n",
    "    normalized_data, scaler = processor.normalize_data(processor.pareto_df)\n",
    "    \n",
    "    # 情景参数设置\n",
    "    scenarios = {\n",
    "        'economic': {'weights': [0.7, 0.1, 0.2], 'max_tourists': 20000, 'carbon_cap': 150},\n",
    "        'environmental': {'weights': [0.2, 0.7, 0.1], 'max_tourists': 15000, 'carbon_cap': 100},\n",
    "        'social': {'weights': [0.1, 0.2, 0.7], 'max_tourists': 18000, 'carbon_cap': 120}\n",
    "    }\n",
    "    \n",
    "    # 运行优化\n",
    "    results = {}\n",
    "    for scenario, params in scenarios.items():\n",
    "        optimizer = TourismOptimizer(normalized_data, params)\n",
    "        res = optimizer.optimize()\n",
    "        if res.success:\n",
    "            results[scenario] = {\n",
    "                'tourists': res.x[0],\n",
    "                'carbon': res.x[1],\n",
    "                'investment': res.x[2],\n",
    "                'profit': res.x[0] * 5000,\n",
    "                'social_score': 1 / (1 + np.exp(-res.x[2]))\n",
    "            }\n",
    "            \n",
    "    # ========== 新增预测可视化 ==========\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(prophet_forecast['ds'], prophet_forecast['yhat'], label='Prophet Forecast')\n",
    "    plt.plot(lstm_forecast, label='LSTM Forecast', linestyle='--')\n",
    "    plt.fill_between(prophet_forecast['ds'], \n",
    "                    prophet_forecast['yhat_lower'],\n",
    "                    prophet_forecast['yhat_upper'],\n",
    "                    alpha=0.2)\n",
    "    plt.title(\"Tourist Number Forecast Comparison\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # 可视化\n",
    "    Visualizer.plot_pareto_front(normalized_data)\n",
    "    Visualizer.plot_scenario_comparison(results)\n",
    "    \n",
    "    # 生成报告\n",
    "    report = f\"\"\"\n",
    "    === 朱诺市可持续旅游发展建议报告 ===\n",
    "    \n",
    "    最优解参数：\n",
    "    - 经济优先情景：游客={results['economic']['tourists']:.0f}人/天, \n",
    "                   碳排放={results['economic']['carbon']:.1f}吨, \n",
    "                   社会评分={results['economic']['social_score']:.2f}\n",
    "    - 环境优先情景：游客={results['environmental']['tourists']:.0f}人/天, \n",
    "                   碳排放={results['environmental']['carbon']:.1f}吨,\n",
    "                   社会评分={results['environmental']['social_score']:.2f}\n",
    "    - 社会优先情景：游客={results['social']['tourists']:.0f}人/天, \n",
    "                   碳排放={results['social']['carbon']:.1f}吨,\n",
    "                   社会评分={results['social']['social_score']:.2f}\n",
    "    \n",
    "    建议措施：\n",
    "    1. 动态游客管理：在冰川区域实施分时预约制，高峰期限流至{results['environmental']['tourists']}人/天\n",
    "    2. 绿色交通计划：将雨林区域的接驳车电动化，预计减少碳排放{results['environmental']['carbon']*0.3:.1f}吨/天\n",
    "    3. 社区基金：将{results['social']['investment']*100:.1f}%的旅游收入用于居民福利\n",
    "    4. 数字导览系统：投资智能设备降低人工压力，提升游客体验评分至{results['social']['social_score']*10:.1f}/10分\n",
    "    \"\"\"\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 动态约束管理\n",
    "def constraints(self):\n",
    "    return [\n",
    "        {'type': 'ineq', 'fun': lambda x: self.max_tourists - x[0]},\n",
    "        {'type': 'ineq', 'fun': lambda x: self.carbon_cap - x[1]},\n",
    "        {'type': 'ineq', 'fun': lambda x: x[2]}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 非线性目标函数\n",
    "def objective(self, x):\n",
    "    profit = x[0] * 5000  # 线性经济收益\n",
    "    carbon_penalty = np.maximum(x[1] - self.carbon_cap, 0) * 1e6  # 分段惩罚函数\n",
    "    social_score = 1 / (1 + np.exp(-x[2]))  # Sigmoid函数映射\n",
    "    return -(self.weights[0]*profit - self.weights[1]*carbon_penalty + self.weights[2]*social_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MCM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
